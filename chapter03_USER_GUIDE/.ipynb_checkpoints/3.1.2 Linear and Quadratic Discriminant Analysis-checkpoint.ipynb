{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Linear and Quadratic Discriminant Analysis\n",
    "\n",
    "Linear Discriminant Analysis (discriminant_analysis.LinearDiscriminantAnalysis) and Quadratic Discriminant Analysis (discriminant_analysis.QuadraticDiscriminantAnalysis) are two classic classiﬁers, with, as their names suggest, a linear and a quadratic decision surface, respectively.\n",
    "\n",
    "These classiﬁers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no hyperparameters to tune.\n",
    "\n",
    "### 1) Dimensionality reduction using Linear Discriminant Analysis\n",
    "\n",
    "discriminant_analysis.LinearDiscriminantAnalysis can be used to perform supervised dimensionality reduction, by projecting the input data to a linear subspace consisting of the directions which maximize the separation between classes (in a precise sense discussed in the mathematics section below). The dimension of the output is necessarily less than the number of classes, so this is, in general, a rather strong dimensionality reduction, and only makes sense in a multiclass setting.\n",
    "\n",
    "### 2) Mathematical formulation of the LDA and QDA classiﬁers\n",
    "\n",
    "More speciﬁcally, for linear and quadratic discriminant analysis, $P(X|y)$ is modeled as a multivariate Gaussian distribution.\n",
    "\n",
    "- In the case of LDA, the Gaussians for each class are assumed to share the same covariance matrix: $\\sum_k = \\sum$ for all $k$ features. This leads to linear decision surfaces, which can be seen by comparing the log-probability ratios.\n",
    "\n",
    "- In the case of QDA, there are no assumptions on the covariance matrices $\\sum_k$ of the Gaussians, leading to quadratic decision surfaces.\n",
    "\n",
    "### 3) Shrinkage\n",
    "\n",
    "Shrinkage is a tool to improve estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator. Shrinkage LDA can be used by setting the shrinkage parameter of the discriminant_analysis. LinearDiscriminantAnalysis class to‘auto’. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf. Note that currently shrinkage only works when setting the solver parameter to ‘lsqr’ or ‘eigen’. \n",
    "\n",
    "The shrinkage parameter can also be manually set between 0 and 1. In particular, \n",
    "- a value of 0 corresponds to no shrinkage (which means the empirical covariance matrix will be used)\n",
    "- a value of 1 corresponds to complete shrinkage (which means that the diagonal matrix of variances will be used as an estimate for the covariance matrix).\n",
    "- Setting this parameter to a value between these two extrema will estimate a shrunk version of the covariance matrix.\n",
    "\n",
    "### 4) Estimation algorithms\n",
    "\n",
    "- The default solver is ‘svd’. It can perform both classiﬁcation and transform, and it does not rely on the calculation of the covariance matrix. This can be an advantage in situations where the number of features is large. However, the ‘svd’ solver cannot be used with shrinkage. \n",
    "- The ‘lsqr’ solver is an efﬁcient algorithm that only works for classiﬁcation. It supports shrinkage.\n",
    "- The ‘eigen’ solver is based on the optimization of the between class scatter to within class scatter ratio. It can be used for both classiﬁcation and transform, and it supports shrinkage. However, the ‘eigen’ solver needs to compute the covariance matrix, so it might not be suitable for situations with a high number of features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
